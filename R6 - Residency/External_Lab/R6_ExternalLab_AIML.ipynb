{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R6_ExternalLab_AIML.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"YYk8NG3yOIT9","colab_type":"text"},"cell_type":"markdown","source":["### A MNIST-like fashion product database\n","\n","In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"tFO6PuxzOIT_","colab_type":"text"},"cell_type":"markdown","source":["### Load tensorflow"]},{"metadata":{"id":"efNjNImfOIUC","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","tf.reset_default_graph()\n","tf.set_random_seed(42)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l9C4aAIGOIUH","colab_type":"code","outputId":"96bcf047-3cc6-422e-ac04-2459a1394380","executionInfo":{"status":"ok","timestamp":1548609028981,"user_tz":-330,"elapsed":4680,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["tf.__version__\n"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.12.0'"]},"metadata":{"tags":[]},"execution_count":59}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"HcoZBStrOIUQ","colab_type":"text"},"cell_type":"markdown","source":["### Collect Data"]},{"metadata":{"id":"XA1WsFSeOIUS","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qnbx7TyQOIUY","colab_type":"code","colab":{}},"cell_type":"code","source":["(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"id":"UbiHj5YPOIUc","colab_type":"code","outputId":"196a2354-9ae6-4222-e363-631a01bea08c","executionInfo":{"status":"ok","timestamp":1548609029516,"user_tz":-330,"elapsed":5003,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["print(testY[0:5])"],"execution_count":62,"outputs":[{"output_type":"stream","text":["[9 2 1 1 6]\n"],"name":"stdout"}]},{"metadata":{"id":"okHeYL7FNb92","colab_type":"code","outputId":"b9e148ce-2a9b-447e-fd41-ea022a27d7d3","executionInfo":{"status":"ok","timestamp":1548609029563,"user_tz":-330,"elapsed":4998,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}},"colab":{"base_uri":"https://localhost:8080/","height":986}},"cell_type":"code","source":["print(trainX[0:1])\n","print(trainX.shape)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","     0   0   0   0   0   0   0   0   0   0   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","     0   0   0   0   0   0   0   0   0   0   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","     0   0   0   0   0   0   0   0   0   0   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73\n","     0   0   1   4   0   0   0   0   1   1   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127\n","    62  54   0   0   0   1   3   4   0   0   3]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176\n","   134 144 123  23   0   0   0   0  12  10   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207\n","   178 107 156 161 109  64  23  77 130  72  15]\n","  [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218\n","   216 216 163 127 121 122 146 141  88 172  66]\n","  [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233\n","   229 223 223 215 213 164 127 123 196 229   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223\n","   228 235 227 224 222 224 221 223 245 173   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213\n","   198 180 212 210 211 213 223 220 243 202   0]\n","  [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218\n","   192 169 227 208 218 224 212 226 197 209  52]\n","  [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218\n","   203 198 221 215 213 222 220 245 119 167  56]\n","  [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228\n","   240 232 213 218 223 234 217 217 209  92   0]\n","  [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222\n","   219 222 221 216 223 229 215 218 255  77   0]\n","  [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218\n","   208 211 218 224 223 219 215 224 244 159   0]\n","  [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211\n","   230 224 234 176 188 250 248 233 238 215   0]\n","  [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206\n","   223 255 255 221 234 221 211 220 232 246   0]\n","  [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229\n","   221 188 154 191 210 204 209 222 228 225   0]\n","  [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106\n","   117 168 219 221 215 217 223 223 224 229  29]\n","  [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227\n","   245 239 223 218 212 209 222 220 221 230  67]\n","  [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225\n","   216 199 206 186 181 177 172 181 205 206 115]\n","  [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194\n","   191 195 191 198 192 176 156 167 177 210  92]\n","  [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204\n","   209 210 210 211 188 188 194 192 216 170   0]\n","  [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191\n","   179 182 182 181 176 166 168  99  58   0   0]\n","  [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0\n","     0   0   0   0   0   0   0   0   0   0   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","     0   0   0   0   0   0   0   0   0   0   0]\n","  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","     0   0   0   0   0   0   0   0   0   0   0]]]\n","(60000, 28, 28)\n"],"name":"stdout"}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"lDAYzkwyOIUj","colab_type":"text"},"cell_type":"markdown","source":["### Convert both training and testing labels into one-hot vectors.\n","\n","**Hint:** check **tf.keras.utils.to_categorical()**"]},{"metadata":{"id":"6yGgbwukPozL","colab_type":"code","outputId":"1e7f036c-cf24-4ce2-c0eb-ef01a635e270","executionInfo":{"status":"ok","timestamp":1548609029590,"user_tz":-330,"elapsed":4964,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["trainY = tf.keras.utils.to_categorical(trainY)\n","print(trainY.shape)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["(60000, 10)\n"],"name":"stdout"}]},{"metadata":{"id":"vBlfYlANOIUk","colab_type":"code","outputId":"33ec93df-f5ae-48db-cb47-497cc7f51606","executionInfo":{"status":"ok","timestamp":1548609029591,"user_tz":-330,"elapsed":3861,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["testY=tf.keras.utils.to_categorical(testY)\n","print(testY.shape)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["(10000, 10)\n"],"name":"stdout"}]},{"metadata":{"scrolled":true,"slideshow":{"slide_type":"fragment"},"id":"RHV3b9mzOIUq","colab_type":"code","outputId":"44ef5ec6-93eb-46df-f1a8-d28844c2d801","executionInfo":{"status":"ok","timestamp":1548609029592,"user_tz":-330,"elapsed":3648,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["print(trainY.shape)\n","print('First 5 examples now are: ', trainY[0:5])"],"execution_count":66,"outputs":[{"output_type":"stream","text":["(60000, 10)\n","First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"FwhQ8e7VOIUw","colab_type":"text"},"cell_type":"markdown","source":["### Visualize the data\n","\n","Plot first 10 images in the triaining set and their labels."]},{"metadata":{"id":"6uNo8crypL3P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":98},"outputId":"38837bf7-d874-41e7-8353-84d4effc06da","executionInfo":{"status":"ok","timestamp":1548609030891,"user_tz":-330,"elapsed":4839,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","fig=plt.figure(figsize=(10, 1))\n","columns = 10\n","rows = 1\n","for i in range(1, columns*rows+1):\n","    grid_data = trainX[i-1].reshape(28,28)\n","    fig.add_subplot(rows, columns, i)\n","    \n","    plt.imshow(grid_data, interpolation=\"none\", cmap = \"gray\")\n","plt.show()"],"execution_count":67,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAlAAAABRCAYAAAAdIZjJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXNwAAAAASUVORK5CYII=\n","text/plain":["<Figure size 720x72 with 10 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"tM_wgj2g3KCK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6ff29374-bc2f-4e9e-a70c-82499c8c27ab","executionInfo":{"status":"ok","timestamp":1548609030894,"user_tz":-330,"elapsed":4443,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["#labels\n","#The [0][0] indexing is just to ditch the structure (a tuple with an array) returned by np.where\n","[np.where(r==1)[0][0] for r in trainY[0:10]]"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[9, 0, 0, 3, 0, 2, 7, 2, 5, 5]"]},"metadata":{"tags":[]},"execution_count":68}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"l4TbJGeSOIU4","colab_type":"text"},"cell_type":"markdown","source":["### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."]},{"metadata":{"id":"Ac06XZZTOIU6","colab_type":"code","colab":{}},"cell_type":"code","source":["#Initialize Sequential model\n","model = tf.keras.models.Sequential()\n","\n","#Reshape data from 2D to 1D -> 28x28 to 784\n","#shape is 3 dimensions last space is for the number of inputs, this the placeholder\n","#if its a colored image we can give four dimension ex: (28,28,3,)... there is only one pixel for gray scale(28,28,1,)\n","model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","\n","\n","#Add Dense Layer which provides 10 Outputs after applying softmax, change it to sigmoid if the categories are 2(yes/no) \n","model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","#Comile the model #categorical crossentropy when we have muultiple categories #loss keras gives by default on fitting but if u also want to get accuracy, you can specify in metrics.\n","model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"3hQpLv3aOIU_","colab_type":"text"},"cell_type":"markdown","source":["### Execute the model using model.fit()"]},{"metadata":{"id":"O59C_-IgOIVB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1071},"outputId":"8116841c-9172-40c7-d38e-b1766c9f16c9","executionInfo":{"status":"ok","timestamp":1548609222878,"user_tz":-330,"elapsed":196310,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["#epochs is the number of iterations\n","model.fit(trainX, trainY, \n","          validation_data=(testX, testY), \n","          epochs=30,\n","          batch_size=32)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/30\n","60000/60000 [==============================] - 7s 110us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 2/30\n","60000/60000 [==============================] - 7s 109us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 3/30\n","60000/60000 [==============================] - 6s 108us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 4/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 5/30\n","60000/60000 [==============================] - 7s 113us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 6/30\n","60000/60000 [==============================] - 6s 107us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 7/30\n","60000/60000 [==============================] - 6s 107us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 8/30\n","60000/60000 [==============================] - 6s 107us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 9/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 10/30\n","60000/60000 [==============================] - 6s 107us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 11/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 12/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 13/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 14/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 15/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 16/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 17/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 18/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 19/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 20/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 21/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 22/30\n","60000/60000 [==============================] - 6s 106us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 23/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 24/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 25/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 26/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 27/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 28/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 29/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n","Epoch 30/30\n","60000/60000 [==============================] - 6s 105us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efe019a2ac8>"]},"metadata":{"tags":[]},"execution_count":70}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"JdzDtGwDOIVF","colab_type":"text"},"cell_type":"markdown","source":["### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."]},{"metadata":{"id":"kndfpdidOIVI","colab_type":"code","colab":{}},"cell_type":"code","source":["#Initialize Sequential model\n","model = tf.keras.models.Sequential()\n","\n","#Reshape data from 2D to 1D -> 28x28 to 784\n","\n","model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","#Normalize the data #might not be needed, as this case already has the data in the range 0-255, which is the purpose of normalisation.\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","#Add Dense Layer which provides 10 Outputs after applying softmax, change it to sigmoid if the categories are 2(yes/no) \n","model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","\n","\n","#Compile the model #categorical crossentropy when we have muultiple categories #loss keras gives by default on fitting but if u also want to get accuracy, you can specify in metrics.\n","model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"mwk3T5LJOIVN","colab_type":"text"},"cell_type":"markdown","source":["### Execute the model"]},{"metadata":{"id":"uuAzn_dnBDY_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1071},"outputId":"ed47aba2-dcb5-4d0c-de34-1e9004752c41","executionInfo":{"status":"ok","timestamp":1548609441085,"user_tz":-330,"elapsed":414381,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["model.fit(trainX, trainY, \n","          epochs=30,validation_data=(testX,testY),\n","          batch_size=32)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/30\n","60000/60000 [==============================] - 7s 124us/step - loss: 0.4086 - acc: 0.8552 - val_loss: 0.4592 - val_acc: 0.8420\n","Epoch 2/30\n","60000/60000 [==============================] - 7s 121us/step - loss: 0.4112 - acc: 0.8547 - val_loss: 0.4769 - val_acc: 0.8363\n","Epoch 3/30\n","60000/60000 [==============================] - 7s 121us/step - loss: 0.4086 - acc: 0.8567 - val_loss: 0.4683 - val_acc: 0.8413\n","Epoch 4/30\n","60000/60000 [==============================] - 8s 131us/step - loss: 0.4083 - acc: 0.8576 - val_loss: 0.4630 - val_acc: 0.8411\n","Epoch 5/30\n","60000/60000 [==============================] - 7s 123us/step - loss: 0.4070 - acc: 0.8570 - val_loss: 0.4769 - val_acc: 0.8393\n","Epoch 6/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4074 - acc: 0.8559 - val_loss: 0.4595 - val_acc: 0.8418\n","Epoch 7/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4086 - acc: 0.8561 - val_loss: 0.4671 - val_acc: 0.8431\n","Epoch 8/30\n","60000/60000 [==============================] - 7s 121us/step - loss: 0.4092 - acc: 0.8561 - val_loss: 0.4715 - val_acc: 0.8414\n","Epoch 9/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4087 - acc: 0.8564 - val_loss: 0.4751 - val_acc: 0.8387\n","Epoch 10/30\n","60000/60000 [==============================] - 7s 122us/step - loss: 0.4071 - acc: 0.8576 - val_loss: 0.4657 - val_acc: 0.8383\n","Epoch 11/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4070 - acc: 0.8576 - val_loss: 0.4708 - val_acc: 0.8398\n","Epoch 12/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4070 - acc: 0.8565 - val_loss: 0.4654 - val_acc: 0.8380\n","Epoch 13/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4070 - acc: 0.8555 - val_loss: 0.4744 - val_acc: 0.8397\n","Epoch 14/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4063 - acc: 0.8568 - val_loss: 0.4753 - val_acc: 0.8396\n","Epoch 15/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4060 - acc: 0.8570 - val_loss: 0.4655 - val_acc: 0.8390\n","Epoch 16/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4060 - acc: 0.8571 - val_loss: 0.4861 - val_acc: 0.8378\n","Epoch 17/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4048 - acc: 0.8583 - val_loss: 0.4733 - val_acc: 0.8405\n","Epoch 18/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4068 - acc: 0.8573 - val_loss: 0.4607 - val_acc: 0.8425\n","Epoch 19/30\n","60000/60000 [==============================] - 7s 122us/step - loss: 0.4048 - acc: 0.8563 - val_loss: 0.4699 - val_acc: 0.8406\n","Epoch 20/30\n","60000/60000 [==============================] - 8s 139us/step - loss: 0.4053 - acc: 0.8570 - val_loss: 0.4713 - val_acc: 0.8412\n","Epoch 21/30\n","60000/60000 [==============================] - 7s 122us/step - loss: 0.4041 - acc: 0.8580 - val_loss: 0.4669 - val_acc: 0.8411\n","Epoch 22/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4049 - acc: 0.8568 - val_loss: 0.4725 - val_acc: 0.8367\n","Epoch 23/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4053 - acc: 0.8576 - val_loss: 0.4724 - val_acc: 0.8424\n","Epoch 24/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4066 - acc: 0.8570 - val_loss: 0.4713 - val_acc: 0.8387\n","Epoch 25/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.4037 - acc: 0.8570 - val_loss: 0.4685 - val_acc: 0.8398\n","Epoch 26/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4030 - acc: 0.8585 - val_loss: 0.4735 - val_acc: 0.8362\n","Epoch 27/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4032 - acc: 0.8587 - val_loss: 0.4729 - val_acc: 0.8370\n","Epoch 28/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4057 - acc: 0.8563 - val_loss: 0.4715 - val_acc: 0.8421\n","Epoch 29/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4015 - acc: 0.8589 - val_loss: 0.4900 - val_acc: 0.8352\n","Epoch 30/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4025 - acc: 0.8586 - val_loss: 0.4810 - val_acc: 0.8390\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efe016a0550>"]},"metadata":{"tags":[]},"execution_count":72}]},{"metadata":{"id":"Py-KwkmjOIVU","colab_type":"text"},"cell_type":"markdown","source":["### Customize the learning rate to 0.001 in sgd optimizer and run the model"]},{"metadata":{"id":"yLXUE9jWOIVV","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#Initialize Sequential model\n","model = tf.keras.models.Sequential()\n","\n","#Reshape data from 2D to 1D -> 28x28 to 784\n","\n","model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","#Normalize the data #might not be needed, as this case already has the data in the range 0-255, which is the purpose of normalisation.\n","model.add(tf.keras.layers.BatchNormalization())\n","\n","#Add Dense Layer which provides 10 Outputs after applying softmax, change it to sigmoid if the categories are 2(yes/no) \n","model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","#Comile the model #categorical crossentropy when we have muultiple categories #loss keras gives by default on fitting but if u also want to get accuracy, you can specify in metrics.\n","model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","\n","#Create optimizer with non-default learning rate\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n","\n","\n","#Compile the model\n","model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pJUqA5T4OIVc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1071},"outputId":"fd1487f0-7724-4ce6-eaa7-ea411b1855c3","executionInfo":{"status":"ok","timestamp":1548609656273,"user_tz":-330,"elapsed":629468,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["model.fit(trainX, trainY, \n","          validation_data=(testX, testY), \n","          epochs=30,\n","          batch_size=32)"],"execution_count":74,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/30\n","60000/60000 [==============================] - 7s 122us/step - loss: 0.9232 - acc: 0.6898 - val_loss: 0.6972 - val_acc: 0.7616\n","Epoch 2/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.6467 - acc: 0.7792 - val_loss: 0.6146 - val_acc: 0.7897\n","Epoch 3/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.5896 - acc: 0.7994 - val_loss: 0.5794 - val_acc: 0.8021\n","Epoch 4/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.5605 - acc: 0.8079 - val_loss: 0.5526 - val_acc: 0.8102\n","Epoch 5/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.5379 - acc: 0.8159 - val_loss: 0.5381 - val_acc: 0.8138\n","Epoch 6/30\n","60000/60000 [==============================] - 7s 120us/step - loss: 0.5248 - acc: 0.8194 - val_loss: 0.5330 - val_acc: 0.8167\n","Epoch 7/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.5167 - acc: 0.8224 - val_loss: 0.5222 - val_acc: 0.8199\n","Epoch 8/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.5065 - acc: 0.8268 - val_loss: 0.5139 - val_acc: 0.8220\n","Epoch 9/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.5007 - acc: 0.8283 - val_loss: 0.5095 - val_acc: 0.8235\n","Epoch 10/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4947 - acc: 0.8302 - val_loss: 0.5064 - val_acc: 0.8246\n","Epoch 11/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4903 - acc: 0.8325 - val_loss: 0.5011 - val_acc: 0.8261\n","Epoch 12/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4840 - acc: 0.8345 - val_loss: 0.4990 - val_acc: 0.8285\n","Epoch 13/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4813 - acc: 0.8357 - val_loss: 0.4957 - val_acc: 0.8276\n","Epoch 14/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4780 - acc: 0.8363 - val_loss: 0.4924 - val_acc: 0.8292\n","Epoch 15/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4717 - acc: 0.8377 - val_loss: 0.4881 - val_acc: 0.8293\n","Epoch 16/30\n","60000/60000 [==============================] - 7s 123us/step - loss: 0.4707 - acc: 0.8382 - val_loss: 0.4914 - val_acc: 0.8304\n","Epoch 17/30\n","60000/60000 [==============================] - 8s 127us/step - loss: 0.4673 - acc: 0.8394 - val_loss: 0.4864 - val_acc: 0.8296\n","Epoch 18/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4656 - acc: 0.8405 - val_loss: 0.4857 - val_acc: 0.8309\n","Epoch 19/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4637 - acc: 0.8403 - val_loss: 0.4814 - val_acc: 0.8324\n","Epoch 20/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4625 - acc: 0.8425 - val_loss: 0.4804 - val_acc: 0.8308\n","Epoch 21/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4609 - acc: 0.8427 - val_loss: 0.4847 - val_acc: 0.8322\n","Epoch 22/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4561 - acc: 0.8429 - val_loss: 0.4811 - val_acc: 0.8333\n","Epoch 23/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4571 - acc: 0.8422 - val_loss: 0.4799 - val_acc: 0.8321\n","Epoch 24/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4543 - acc: 0.8447 - val_loss: 0.4753 - val_acc: 0.8337\n","Epoch 25/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4536 - acc: 0.8435 - val_loss: 0.4783 - val_acc: 0.8340\n","Epoch 26/30\n","60000/60000 [==============================] - 7s 118us/step - loss: 0.4528 - acc: 0.8440 - val_loss: 0.4747 - val_acc: 0.8331\n","Epoch 27/30\n","60000/60000 [==============================] - 7s 117us/step - loss: 0.4517 - acc: 0.8444 - val_loss: 0.4749 - val_acc: 0.8338\n","Epoch 28/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4486 - acc: 0.8471 - val_loss: 0.4697 - val_acc: 0.8345\n","Epoch 29/30\n","60000/60000 [==============================] - 7s 119us/step - loss: 0.4501 - acc: 0.8453 - val_loss: 0.4720 - val_acc: 0.8353\n","Epoch 30/30\n","60000/60000 [==============================] - 7s 117us/step - loss: 0.4473 - acc: 0.8456 - val_loss: 0.4769 - val_acc: 0.8347\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efe00ada748>"]},"metadata":{"tags":[]},"execution_count":74}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"j9CSqKvpOIVk","colab_type":"text"},"cell_type":"markdown","source":["### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."]},{"metadata":{"id":"GGAad54JOIVm","colab_type":"code","colab":{}},"cell_type":"code","source":["#Initialize Sequential model\n","model1 = tf.keras.models.Sequential()\n","\n","#Reshape data from 2D to 1D -> 28x28 to 784\n","model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","#Normalize the data\n","model1.add(tf.keras.layers.BatchNormalization())\n","\n","#Add 1st hidden layer\n","model1.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n","\n","#Add 2nd hidden layer\n","model1.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n","\n","#Add OUTPUT layer\n","model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","#Create optimizer with non-default learning rate\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n","\n","#Compile the model\n","model1.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MQ7oIymROIVp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1054},"outputId":"1a38cdc1-d038-4351-e02a-1e405c5cae42","executionInfo":{"status":"ok","timestamp":1548609885512,"user_tz":-330,"elapsed":858635,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["model1.fit(trainX,trainY,          \n","          epochs=30,\n","          batch_size=32)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","60000/60000 [==============================] - 8s 127us/step - loss: 0.2545 - acc: 0.9071\n","Epoch 2/30\n","60000/60000 [==============================] - 8s 128us/step - loss: 0.2502 - acc: 0.9085\n","Epoch 3/30\n","60000/60000 [==============================] - 9s 145us/step - loss: 0.2471 - acc: 0.9100\n","Epoch 4/30\n","60000/60000 [==============================] - 8s 126us/step - loss: 0.2443 - acc: 0.9100\n","Epoch 5/30\n","60000/60000 [==============================] - 8s 126us/step - loss: 0.2411 - acc: 0.9127\n","Epoch 6/30\n","60000/60000 [==============================] - 7s 125us/step - loss: 0.2369 - acc: 0.9139\n","Epoch 7/30\n","60000/60000 [==============================] - 7s 125us/step - loss: 0.2336 - acc: 0.9141\n","Epoch 8/30\n","60000/60000 [==============================] - 7s 124us/step - loss: 0.2303 - acc: 0.9154\n","Epoch 9/30\n","60000/60000 [==============================] - 7s 124us/step - loss: 0.2283 - acc: 0.9160\n","Epoch 10/30\n","60000/60000 [==============================] - 8s 125us/step - loss: 0.2240 - acc: 0.9185\n","Epoch 11/30\n","60000/60000 [==============================] - 7s 125us/step - loss: 0.2211 - acc: 0.9189\n","Epoch 12/30\n","60000/60000 [==============================] - 8s 126us/step - loss: 0.2197 - acc: 0.9187\n","Epoch 13/30\n","60000/60000 [==============================] - 8s 125us/step - loss: 0.2127 - acc: 0.9221\n","Epoch 14/30\n","60000/60000 [==============================] - 8s 126us/step - loss: 0.2128 - acc: 0.9227\n","Epoch 15/30\n","60000/60000 [==============================] - 8s 127us/step - loss: 0.2102 - acc: 0.9235\n","Epoch 16/30\n","60000/60000 [==============================] - 8s 126us/step - loss: 0.2060 - acc: 0.9254\n","Epoch 17/30\n","60000/60000 [==============================] - 8s 127us/step - loss: 0.2057 - acc: 0.9241\n","Epoch 18/30\n","60000/60000 [==============================] - 8s 127us/step - loss: 0.2039 - acc: 0.9262\n","Epoch 19/30\n","60000/60000 [==============================] - 8s 129us/step - loss: 0.1987 - acc: 0.9277\n","Epoch 20/30\n","60000/60000 [==============================] - 8s 128us/step - loss: 0.1998 - acc: 0.9269\n","Epoch 21/30\n","60000/60000 [==============================] - 8s 129us/step - loss: 0.1958 - acc: 0.9277\n","Epoch 22/30\n","60000/60000 [==============================] - 8s 127us/step - loss: 0.1936 - acc: 0.9294\n","Epoch 23/30\n","60000/60000 [==============================] - 8s 126us/step - loss: 0.1896 - acc: 0.9308\n","Epoch 24/30\n","60000/60000 [==============================] - 7s 124us/step - loss: 0.1874 - acc: 0.9324\n","Epoch 25/30\n","60000/60000 [==============================] - 8s 125us/step - loss: 0.1868 - acc: 0.9317\n","Epoch 26/30\n","60000/60000 [==============================] - 7s 125us/step - loss: 0.1867 - acc: 0.9322\n","Epoch 27/30\n","60000/60000 [==============================] - 8s 133us/step - loss: 0.1833 - acc: 0.9328\n","Epoch 28/30\n","60000/60000 [==============================] - 8s 131us/step - loss: 0.1796 - acc: 0.9348\n","Epoch 29/30\n","60000/60000 [==============================] - 8s 126us/step - loss: 0.1744 - acc: 0.9371\n","Epoch 30/30\n","60000/60000 [==============================] - 8s 127us/step - loss: 0.1745 - acc: 0.9363\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7efe00ada1d0>"]},"metadata":{"tags":[]},"execution_count":76}]},{"metadata":{"id":"X-O-fFxnOIVt","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"BiP7IL52OIVw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"Nr2YsZV0OIV0","colab_type":"text"},"cell_type":"markdown","source":["## Review model"]},{"metadata":{"id":"h4ojW6-oOIV2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"4e3c9d24-2f4f-400a-d62a-3941dee775e4","executionInfo":{"status":"ok","timestamp":1548609885521,"user_tz":-330,"elapsed":858559,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["model1.summary()"],"execution_count":77,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","reshape_3 (Reshape)          (None, 784)               0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 784)               3136      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 100)               78500     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                1010      \n","=================================================================\n","Total params: 92,746\n","Trainable params: 91,178\n","Non-trainable params: 1,568\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"gfFGmbZLOIV5","colab_type":"text"},"cell_type":"markdown","source":["### Run the model"]},{"metadata":{"id":"bIkbMEN5OIV7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"2e1f463d-330c-4810-9a3a-513a540f3661","executionInfo":{"status":"ok","timestamp":1548609887201,"user_tz":-330,"elapsed":860208,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["model1.evaluate(testX,testY)"],"execution_count":78,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 1s 68us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.3410659310221672, 0.8873]"]},"metadata":{"tags":[]},"execution_count":78}]},{"metadata":{"id":"c1ynwwcmtQ5O","colab_type":"code","colab":{}},"cell_type":"code","source":["predicted_classes = model1.predict_classes(testX,verbose=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CgJ-_bjbtWfI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"796ac462-deda-4db7-e1f7-9d3260b9c199","executionInfo":{"status":"ok","timestamp":1548609887217,"user_tz":-330,"elapsed":860189,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["predicted_classes.shape, testY.shape"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((10000,), (10000, 10))"]},"metadata":{"tags":[]},"execution_count":80}]},{"metadata":{"id":"2BZ90rGSvsJ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d4b8c37e-f4c0-4857-a4a7-516c4437b134","executionInfo":{"status":"ok","timestamp":1548609887219,"user_tz":-330,"elapsed":860162,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["#converting testY from (10000,10) to (10000,)\n","test_data_labels = [np.where(r==1)[0][0] for r in testY[:]]\n","test_labels = np.asarray(pred)\n","test_labels.shape"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000,)"]},"metadata":{"tags":[]},"execution_count":81}]},{"metadata":{"id":"UqL_C03IATra","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f388bb42-d8bc-4547-90bd-b12843695783","executionInfo":{"status":"ok","timestamp":1548610402740,"user_tz":-330,"elapsed":811,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["count=0\n","for i in range(0,len(test_labels)):\n","  if(test_labels[i]==predicted_classes[i]):\n","    count+=1\n","\"There are {} correct predictions out of {}\".format(count,10000)\n"],"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'There are 8873 correct predictions out of 10000'"]},"metadata":{"tags":[]},"execution_count":84}]},{"metadata":{"id":"TxjJUPUNGWO0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1969},"outputId":"280031ea-2bd8-43c8-f890-e268a5ba5026","executionInfo":{"status":"ok","timestamp":1548609887228,"user_tz":-330,"elapsed":860135,"user":{"displayName":"Reetika Choradia","photoUrl":"https://lh5.googleusercontent.com/-8nGDA9KS6lM/AAAAAAAAAAI/AAAAAAAADoM/HJGUjZRONws/s64/photo.jpg","userId":"00027226233366543030"}}},"cell_type":"code","source":["import pandas as pd\n","pd.DataFrame(test_labels, predicted_classes)"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows  1 columns</p>\n","</div>"],"text/plain":["    0\n","9   9\n","2   2\n","1   1\n","1   1\n","6   6\n","1   1\n","4   4\n","6   6\n","5   5\n","7   7\n","4   4\n","5   5\n","5   7\n","3   3\n","4   4\n","1   1\n","2   2\n","2   4\n","8   8\n","0   0\n","2   2\n","5   5\n","7   7\n","5   9\n","1   1\n","4   4\n","6   6\n","0   0\n","9   9\n","3   3\n",".. ..\n","2   2\n","6   6\n","2   2\n","7   9\n","7   7\n","8   8\n","5   5\n","0   6\n","9   9\n","0   6\n","0   0\n","0   0\n","8   8\n","1   1\n","3   3\n","2   2\n","7   7\n","5   5\n","8   8\n","2   4\n","5   5\n","0   6\n","8   8\n","9   9\n","1   1\n","9   9\n","1   1\n","8   8\n","1   1\n","5   5\n","\n","[10000 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":83}]}]}